{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to detect subcellular Ca<sup>2+</sup> signals using Flika \n",
    "by Kyle Ellefsen, October 31, 2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is relevant for researchers who record subcellular Ca<sup>2+</sup> signals using fluorescent Ca<sup>2+</sup> indicators.  This algorithm automates the detection and analysis of these brief Ca2+ signals.  This is not a tutorial for researchers looking to analyze global Ca<sup>2+</sup> signals, although I'm planning on creating a tutorial for that, and many of the same concepts apply.\n",
    "\n",
    "In this problem, we will use the threshold-cluster algorithm.  This algorithm is not published, but is modified from the algorithm published in [Ellefsen et al, 2014](http://dx.doi.org/10.1016/j.ceca.2014.06.003).  When using this algorithm, please cite that paper.  The threshold-cluster algorithm can be conceptually divided into two steps.  The first step preprocesses the raw movie and creates three movies.  The second step performs analysis on those movies according to user defined parameters.  I'll break this tutorial into those two steps.  \n",
    "\n",
    "Using this algorithm involves reading and writing code.  Although this algorithm can all be done using Flika's GUI tools (opening windows, clicking buttons, etc.), it is much more efficient for a researcher to write a python file that will automatically perform all these operations.  Therefore, in this tutorial, I will be describing the code you'll need to use in each step.  If you do not know how to code in python, I recommend downloading [anaconda](https://www.continuum.io/downloads), which contains python and many python packages.  Then launch [Spyder](https://github.com/spyder-ide/spyder) (which comes with anaconda), and from within Spyder, run [Flika.py](https://github.com/kyleellefsen/Flika).  All these commands will be executed in the same console that Flika.py is running in. If you have questions about how to do that, email me and I'll help you with setting up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "There are three movies we want to generate as part of the preprocessing step.\n",
    "1. $F/F_0$ Movie\n",
    "2. Normalized Movie\n",
    "3. Binary Movie\n",
    "\n",
    "First, let's generate the $F/F_0$ movie. Each value of the $F/F_0$ movie represents a percent change from baseline fluoresences.  A value of 1 indicates that pixel is currently exactly at baseline fluoresence.  A value of 1.14 indicates a 14% increase above baseline fluorsence. To generate this movie, we will first open our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will subtract the camera's black level.  The black level is the value of a pixel when 0 photons are detected.  There are two common ways to measure black level.  You could turn the laser off at the beginning of your record, and switch it on when you've recorded enough frames to accurately determine the black level.  Or you could measure the values in a black area of your field of view.  Let's say our black level is 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtract(720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations in Flika are performed on the current window, which is either the window that was most recently created or the window that was last clicked on.  \n",
    "\n",
    "Now, for each pixel, we want the percent change from baseline.  To calculate this, we need a measure of baseline fluorescence, during which there is no Ca<sup>2+</sup> activity.  Let's suppose that our cell is quiescent from frame 0 to frame 30.  Then we will take the average image from frame 0 to 30, and divide every image in the movie by that average image.  In Flika, this is performed in a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_window=ratio(150,300,'average'); #ratio(first_frame, nFrames, ratio_type), now we are in F/F0\n",
    "data_window.setName('Data Window dF/F0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we set the variable 'data_window'.  The output of each Flika command returns the new window created by the command, which we can assign to a variable for later use.  We now have our data_window.  \n",
    "\n",
    "The normalized movie should have several special properties that will enable automated signal detection.  The noise for each pixel should be gaussian distributed with a mean of 0 and a standard deviation of 1 ($\\mu = 0; \\sigma =1$).  Since data files won't start off with those properties, we need to transform them. \n",
    "\n",
    "Since we are concerned with only local signals, sometimes we want to remove global signals or other slow noise.  We can exploit the fact that global signals typically have a must slower timecourse than brief local signals, and use a temporal filter to remove slow changes.  We will use the butterworth filter.  In order to determine what parameters we want to use, let's use the the butterworth filter GUI.  Right click and drag on the $F/F_0$ movie window to create an ROI.  Right click in the center of that ROI, and plot the trace.  Then, in the main Flika window, select Process->Filters->Butterworth Filter.  Make sure the Preview checkbox is checked.  Adjust the Low Cutoff Frequency until the global signals are removed, but the local signals are still visible.  Then press the 'Cancel' button and use the parameters you found to perform the filter.  Sometimes this filter can take a few minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "butterworth_filter(1,.03,1,keepSourceWindow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't need to filter your data, just subtract 1 from each value so that the noise is centered around 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtract(1) #Don't do this if you used the filter above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now our movie should have its noise centered around 0.  We want the standard deviation of our noise to be equal to 1, so we'll find a quiescent section of our movie and ratio by the standard deviation, similar to when we ratioed by the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio(100,100,'standard deviation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our butterworth filter created artifacts at the beginning and end of the movie.  Let's eliminate those by setting the values at the beginning and end of the movie to 0. 'mt' is a variable that represents number of frames of our movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_window=set_value(0,0,100) #to get rid of butterworth artifact at the beginning of the movie\n",
    "norm_window=set_value(0,mt-150,mt-1) #to get rid of butterworth artifact at the end of the movie\n",
    "norm_window.setName('Normalized Window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We're most of the way there.  We have our $F/F_0$ Movie and our Normalized Movie.  The last movie we need is the Binary Movie.  If we threshold our normalized window, so that all the pixels below a certain value are set to 0 and all pixels above that value are set to 1, the result is a binary movie.  Picking the value of the threshold is about balance.  If the threshold is too high, you will miss detecting small events.  If the threshold is too low, then calculating the density (described below) will take a very long time.  I've found in practice that a value of around 1 works well, but this will vary depending on your movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_window=threshold(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Clustering\n",
    "The second half of the algorithm requires only those three movies we created earlier:  \n",
    "1. $F/F_0$ Movie\n",
    "2. Normalized Movie\n",
    "3. Binary Movie\n",
    "\n",
    "\n",
    "\n",
    "We pass these three movies into the 'threshold_cluster()' function, along with some constants, and the algorithm detects subcellular signals! And like many black boxes, for it to work correctly, we have to know what it's doing under the hood.  So what does this function do?\n",
    "\n",
    "### Density Calculation\n",
    "First it uses the binary movie to calculate density.  The logic behind this is as follows: Where there is no signal, the pixels in the binary movie which are true should be randomly, uniformly spread.  If you pick any point anywhere in the image and draw a sphere around that point (like a circle in the x and y dimensions, but also extended into the time dimension), and count the number of true pixels inside that sphere, the number of pixels will be distributed according to the binomial distribution. The specifics of the math doesn't really matter, what's important is that this number (the number of true pixels inside a sphere without a signal) will be different than the number of true pixels inside a sphere when there is a signal.  In the presence of a signal, the number of true pixels will be higher.  \n",
    "\n",
    "To get the density, we calculate, for each true pixel, the number of true pixels in a sphere around it.  We then store that value in another movie at the same location.  The result looks like this:\n",
    "\n",
    "![binary to density](images/binary_to_density.PNG)\n",
    "\n",
    "You can see that the pixels that occur at high density stand out. After the density transformation they have a much greater value relative to the background true pixels than in the $F/F_0$ Movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "The clustering algorithm is based on the one published by [Rodriguez and Laio, 2014](doi.org/10.1126/science.1242072). The basic idea is simple.  We have a bunch of pixels with positive values from our density transformation.  For each pixel, we find nearest pixel with a higher value.  For pixels that are on the edge of an event, those pixels with higher values will be close.  See the little cartoon I made below.  The green arrows show pixels pointing to the pixel identified as having a higher value.\n",
    "![clustering cartoon](images/clustering_cartoon.png)\n",
    "One arrow stands out.  One pixel near the center of the cluster has the highest value, so the arrow from it is much much longer than any of the other arrows in the cluster. In general, all clusers should have this property: one pixel near the center should be pointing to a pixel that is pointing far away, every other pixel in the cluster will have small arrows.  From this principle, we can find clusters.  All we need to do is identify the pixels that have abnormally high distances to the closest pixel of higher value.  These pixels should also have an abnormally high density, since many isolated pixels will also have abnormally high arrows.  I've simulated a few signals and plotted the density of each true pixel vs the smallest distance to a denser point.\n",
    "\n",
    "![Density vs Distance](images/density_vs_distance.png)\n",
    "\n",
    "You can see that there are several points that have a high density and distance.  These are the centers of the clusters.  The clustering algorithm considers all pixels that point to these centers to be part of these clusters.  Circle the points at the top right of the graph, and Flika will output a movie where each cluster is colored differently.  This way you can be sure that you've clustered how you would like.  \n",
    "\n",
    "![Density vs Distance (circled)](images/density_vs_distance_circled.png)\n",
    "\n",
    "The pixels that are considered 'centers' will be colored green after circling.  Red indicates that there were fewer than 10 pixels in the cluster, so that cluster was automatically rejected.  \n",
    "\n",
    "![clusters](images/clusters.png)\n",
    "\n",
    "If you don't like the way that you clustered, you can recircle the pixels to recluster.  Once you've got them clustered the way you like, click back on density vs distance window and press enter.  This will bring you to the Puff Analyzer dialog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puff Analyzer\n",
    "If you look back at the $F/F_0$ window, it will have a bunch of red dots on it.  Each one of those dots represents a detected Ca2+ signal.  If you click on one, the Puff Analyzer dialog will display the trace for that signal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
